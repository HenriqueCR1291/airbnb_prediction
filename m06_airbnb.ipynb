{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T19:35:21.931278Z",
     "start_time": "2021-04-21T19:35:21.926280Z"
    }
   },
   "source": [
    "# 0.0. Understanding the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--Goal:\n",
    "    \n",
    "    --1.0 Predict the first destination that the new user will choose\n",
    "    \n",
    "    --Why?\n",
    "        --What is the business model of Airbnb?\n",
    "            --Marketplace (connect people who offer acomodation to whom are seeking a place)\n",
    "            --Offer\n",
    "                --Portfolio size\n",
    "                --Portfolio diversity and density\n",
    "                --Average price\n",
    "                \n",
    "            --Demand\n",
    "                --Number of users\n",
    "                --LTV (lifetime value)\n",
    "                --CAC (client acquisition cost)\n",
    "                \n",
    "                Gross Revenue = (Fee*Number of clients) - CAC\n",
    "                \n",
    "--Solution:\n",
    "    \n",
    "    --Predictive model for the first destination of new user\n",
    "    --1.0 Prediction save in a database\n",
    "    --2.0 API\n",
    "        --Input: User and features\n",
    "        --Output: User and feature with destination prediction\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T01:03:32.298830Z",
     "start_time": "2021-05-10T01:03:31.505883Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install scikit-plot\n",
    "#!pip install imblearn\n",
    "#!pip install delayed\n",
    "#!pip install pandas-profiling\n",
    "#!pip install matplotlib\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn    import model_selection as ms\n",
    "from sklearn    import preprocessing   as pp\n",
    "from sklearn    import metrics         as m\n",
    "from scikitplot import metrics         as mt\n",
    "from scipy      import stats           as ss\n",
    "from imblearn   import under_sampling  as us\n",
    "from imblearn   import over_sampling   as oversamp\n",
    "from imblearn   import combine         as c\n",
    "from keras      import models          as ml\n",
    "from keras      import layers          as l\n",
    "from matplotlib import pyplot          as plt\n",
    "\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T01:03:32.780230Z",
     "start_time": "2021-05-10T01:03:32.382337Z"
    }
   },
   "outputs": [],
   "source": [
    "def cramer_v( x, y ):\n",
    "    cm = pd.crosstab( x, y ).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = ss.chi2_contingency( cm )[0]\n",
    "    chi2corr = max( 0, chi2 - (k-1)*(r-1)/(n-1) )\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt( (chi2corr/n) / ( min( kcorr-1, rcorr-1 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T01:03:54.233877Z",
     "start_time": "2021-05-10T01:03:33.042237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213451, 16)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv('dataset/train_users_2.csv', low_memory=True)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.430Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sessions = pd.read_csv('dataset/sessions.csv', low_memory=True)\n",
    "df_sessions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.433Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.436Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of rows: {}'.format(df1.shape[0]))\n",
    "print('Number of columns: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.438Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of rows: {}'.format(df_sessions.shape[0]))\n",
    "print('Number of columns: {}'.format(df_sessions.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.442Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.444Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sessions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. NA Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.447Z"
    }
   },
   "outputs": [],
   "source": [
    "df1.isna().sum()/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.450Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sessions.isna().sum()/len(df_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.452Z"
    }
   },
   "outputs": [],
   "source": [
    "#date_first_booking\n",
    "date_first_booking_max = pd.to_datetime(df1['date_first_booking']).max().strftime('%Y-%m-%d')\n",
    "df1['date_first_booking'] = df1['date_first_booking'].fillna(date_first_booking_max)\n",
    "\n",
    "\n",
    "# ========== User =================\n",
    "# age\n",
    "df1 = df1[( df1['age'] > 15 ) & ( df1['age'] < 120 )]\n",
    "avg_age = df1['age'].mean()\n",
    "df1['age'] = df1['age'].fillna( avg_age )\n",
    "\n",
    "#first_affiliate_tracked\n",
    "df1 = df1[~df1['first_affiliate_tracked'].isna()]\n",
    "\n",
    "\n",
    "# ========== Sessions =================\n",
    "#user_id\n",
    "df_sessions = df_sessions[~df_sessions['user_id'].isna()]\n",
    "\n",
    "#action\n",
    "df_sessions = df_sessions[~df_sessions['action'].isna()]\n",
    "\n",
    "#action_type\n",
    "df_sessions = df_sessions[~df_sessions['action_type'].isna()]\n",
    "\n",
    "#action_detail\n",
    "df_sessions = df_sessions[~df_sessions['action_detail'].isna()]\n",
    "\n",
    "#secs_elapsed\n",
    "df_sessions = df_sessions[~df_sessions['secs_elapsed'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T20:26:36.247449Z",
     "start_time": "2021-04-21T20:26:36.244451Z"
    }
   },
   "source": [
    "## 1.4. Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.455Z"
    }
   },
   "outputs": [],
   "source": [
    " df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.458Z"
    }
   },
   "outputs": [],
   "source": [
    "#date_account_created\n",
    "df1['date_account_created'] = pd.to_datetime(df1['date_account_created'])\n",
    "\n",
    "#timestamp_first_active\n",
    "df1['timestamp_first_active'] = pd.to_datetime(df1['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "#date_first_booking\n",
    "df1['date_first_booking'] = pd.to_datetime(df1['date_first_booking'])\n",
    "\n",
    "#age\n",
    "df1['age'] = df1['age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Check Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.461Z"
    }
   },
   "outputs": [],
   "source": [
    "df1['country_destination'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.466Z"
    }
   },
   "outputs": [],
   "source": [
    "#Users\n",
    "num_attributes = df1.select_dtypes(include=['int64','float64'])\n",
    "cat_attributes = df1.select_dtypes(exclude=['int64','float64','datetime64[ns]'])\n",
    "time_attributes = df1.select_dtypes(include=['datetime64[ns]'])\n",
    "\n",
    "#Sessions\n",
    "num_attributes_sessions = df_sessions.select_dtypes(include=['int64','float64'])\n",
    "cat_attributes_sessions = df_sessions.select_dtypes(exclude=['int64','float64','datetime64[ns]'])\n",
    "time_attributes_sessions = df_sessions.select_dtypes(include=['datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1 Numerical - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.469Z"
    }
   },
   "outputs": [],
   "source": [
    "#Central Tendency - Mean, Median\n",
    "ct1 = pd.DataFrame(num_attributes.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(num_attributes.apply(np.median)).T\n",
    "\n",
    "#Dispersions - Std, Min, Max, Range, Skew, Kurtosis\n",
    "d1 = pd.DataFrame(num_attributes.apply(np.std)).T\n",
    "d2 = pd.DataFrame(num_attributes.apply(min)).T\n",
    "d3 = pd.DataFrame(num_attributes.apply(max)).T\n",
    "d4 = pd.DataFrame(num_attributes.apply(lambda x: x.max() - x.min())).T\n",
    "d5 = pd.DataFrame(num_attributes.apply(lambda x: x.skew())).T\n",
    "d6 = pd.DataFrame(num_attributes.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "#Concat\n",
    "ct = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6]).T.reset_index()\n",
    "ct.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2 Numerical - Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.473Z"
    }
   },
   "outputs": [],
   "source": [
    "#Central Tendency - Mean, Median\n",
    "ct1 = pd.DataFrame(num_attributes_sessions.apply(np.mean)).T\n",
    "ct2 = pd.DataFrame(num_attributes_sessions.apply(np.median)).T\n",
    "\n",
    "#Dispersions - Std, Min, Max, Range, Skew, Kurtosis\n",
    "d1 = pd.DataFrame(num_attributes_sessions.apply(np.std)).T\n",
    "d2 = pd.DataFrame(num_attributes_sessions.apply(min)).T\n",
    "d3 = pd.DataFrame(num_attributes_sessions.apply(max)).T\n",
    "d4 = pd.DataFrame(num_attributes_sessions.apply(lambda x: x.max() - x.min())).T\n",
    "d5 = pd.DataFrame(num_attributes_sessions.apply(lambda x: x.skew())).T\n",
    "d6 = pd.DataFrame(num_attributes_sessions.apply(lambda x: x.kurtosis())).T\n",
    "\n",
    "#Concat\n",
    "ct = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6]).T.reset_index()\n",
    "ct.columns = ['attributes', 'min', 'max', 'range', 'mean', 'median', 'std', 'skew', 'kurtosis']\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.3. Categorical - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.477Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_attributes.drop(['id','age'], axis=1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.4 - Categorical - Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.481Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_attributes_sessions.drop('user_id', axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.483Z"
    }
   },
   "outputs": [],
   "source": [
    "#list of attributes for Cramer's V correlation\n",
    "cat_attributes_list = cat_attributes_sessions.drop('user_id', axis=1).columns.tolist()\n",
    "\n",
    "corr_dict = {}\n",
    "for i in range(len(cat_attributes_list)):\n",
    "    corr_list = []\n",
    "    for j in range(len(cat_attributes_list)):\n",
    "        ref = cat_attributes_list[i]\n",
    "        feat = cat_attributes_list[j]\n",
    "        \n",
    "        # correlation\n",
    "        corr = cramer_v(cat_attributes_sessions[ref], cat_attributes_sessions[feat])\n",
    "        \n",
    "        # append a list\n",
    "        corr_list.append(corr)\n",
    "    \n",
    "    # appende a correlation list for each ref attributs\n",
    "    corr_dict[ref] = corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.486Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_dict[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.489Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_dict[ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.492Z"
    }
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame(corr_dict)\n",
    "d = d.set_index(d.columns)\n",
    "sns.heatmap(d, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.495Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Create New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.499Z"
    }
   },
   "outputs": [],
   "source": [
    "#days from first active up to first booking\n",
    "df2['first_active'] = pd.to_datetime(df2['timestamp_first_active'].dt.strftime('%Y-%m-%d'))\n",
    "df2['days_from_first_active_until_booking'] = (df2['date_first_booking'] - df2['first_active']).apply(lambda x: x.days)\n",
    "\n",
    "#days from first active upt to account created\n",
    "df2['days_from_first_active_until_account_created'] = (df2['date_account_created'] - df2['first_active']).apply(lambda x: x.days)\n",
    "\n",
    "#days from account createad up to first booking\n",
    "df2['days_from_account_created_until_first_booking'] = (df2['date_first_booking'] - df2['date_account_created']).apply(lambda x: x.days)\n",
    "\n",
    "\n",
    "# ================== First Active ==================\n",
    "#year first active\n",
    "df2['year_first_active'] = df2['first_active'].dt.year\n",
    "\n",
    "#month first active\n",
    "df2['month_first_active'] = df2['first_active'].dt.month\n",
    "\n",
    "#day first active\n",
    "df2['day_first_active'] = df2['first_active'].dt.day\n",
    "\n",
    "#day of week first active\n",
    "df2['day_of_week_first_active'] = df2['first_active'].dt.dayofweek\n",
    "\n",
    "#week of year first active\n",
    "df2['week_of_year_first_active'] = df2['first_active'].dt.isocalendar().week\n",
    "df2['week_of_year_first_active'] = np.asarray(df2['week_of_year_first_active']).astype(np.int64)\n",
    "\n",
    "\n",
    "# ================== First Booking ==================\n",
    "#year first booking\n",
    "df2['year_first_booking'] = df2['date_first_booking'].dt.year\n",
    "\n",
    "#month first booking\n",
    "df2['month_first_booking'] = df2['date_first_booking'].dt.month\n",
    "\n",
    "#day first booking\n",
    "df2['day_first_booking'] = df2['date_first_booking'].dt.day\n",
    "\n",
    "#day of week first booking\n",
    "df2['day_of_week_first_booking'] = df2['date_first_booking'].dt.dayofweek\n",
    "\n",
    "#week of year first booking\n",
    "df2['week_of_year_first_booking'] = df2['date_first_booking'].dt.isocalendar().week\n",
    "df2['week_of_year_first_booking'] = np.asarray(df2['week_of_year_first_booking']).astype(np.int64)\n",
    "\n",
    "\n",
    "# ================== First Account Created =================\n",
    "#year first booking\n",
    "df2['year_account_created'] = df2['date_account_created'].dt.year\n",
    "\n",
    "#month  account_created\n",
    "df2['month_account_created'] = df2['date_account_created'].dt.month\n",
    "\n",
    "#day  account_created\n",
    "df2['day_account_created'] = df2['date_account_created'].dt.day\n",
    "\n",
    "#day of week  account_created\n",
    "df2['day_of_week_account_created'] = df2['date_account_created'].dt.dayofweek\n",
    "\n",
    "#week of year  account_created\n",
    "df2['week_of_year_account_created'] = df2['date_account_created'].dt.isocalendar().week\n",
    "df2['week_of_year_account_created'] = np.asarray(df2['week_of_year_account_created']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.502Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.505Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.509Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filtering rows:\n",
    "# age - greater than 15 and lower than 120 - There are few people over 12O year old   \n",
    "df3 = df3[( df3['age'] > 15 ) & ( df3['age'] < 120 )]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Columns Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.515Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['date_account_created', 'date_account_created', 'date_first_booking', 'timestamp_first_active', 'first_active'] # original datetime\n",
    "df3 = df3.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.521Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "#df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.524Z"
    }
   },
   "outputs": [],
   "source": [
    "#Encoder Categorical Variables\n",
    "ohe = pp.OneHotEncoder()\n",
    "\n",
    "#Numerical\n",
    "col_num = df4.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "#Categorical\n",
    "col_cat = df4.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).drop(['id', 'country_destination'], axis=1).columns.tolist()\n",
    "\n",
    "#encoding\n",
    "df4_dummy = pd.DataFrame(ohe.fit_transform( df4[ col_cat]).toarray(), index=df4.index)\n",
    "\n",
    "#join numerical and categorical\n",
    "df42 = pd.concat([df4[col_num], df4_dummy], axis=1)\n",
    "df42.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.528Z"
    }
   },
   "outputs": [],
   "source": [
    "#ratio_balanced\n",
    "ratio_balanced = {'NDF': 10000}\n",
    "\n",
    "#define sampler\n",
    "undersampling = us.RandomUnderSampler(sampling_strategy=ratio_balanced, random_state=32)\n",
    "\n",
    "#apply sampler\n",
    "X_under, y_under = undersampling.fit_resample(df42, df4['country_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.531Z"
    }
   },
   "outputs": [],
   "source": [
    "df4['country_destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.533Z"
    }
   },
   "outputs": [],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.538Z"
    }
   },
   "outputs": [],
   "source": [
    "#define sampler\n",
    "oversampling = oversamp.RandomOverSampler(sampling_strategy='all', random_state=32)\n",
    "\n",
    "#apply sampler\n",
    "X_over, y_over = oversampling.fit_resample(df42, df4['country_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.541Z"
    }
   },
   "outputs": [],
   "source": [
    "df4['country_destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.544Z"
    }
   },
   "outputs": [],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. SMOTE + TOMEKLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.547Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio_balanced =  {'NDF': 54852,\n",
    "                   'US':  48057,\n",
    "                   'other': 6*7511,\n",
    "                   'FR': 12*3669,\n",
    "                   'IT': 20*2014,\n",
    "                   'GB': 30*1758,\n",
    "                   'ES': 30*1685,\n",
    "                   'CA': 40*1064,\n",
    "                   'DE': 45*841,\n",
    "                   'NL': 80*595,\n",
    "                   'AU': 85*433,\n",
    "                   'PT': 300*157}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.550Z"
    }
   },
   "outputs": [],
   "source": [
    "#define sampler\n",
    "smt = c.SMOTETomek(sampling_strategy=ratio_balanced, random_state=32, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.552Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply sampler\n",
    "#X_smt, y_smt = smt.fit_resample(df42, df4['country_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.554Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle.dump(X_smt, open('X_smt.pkl','wb'))\n",
    "#pickle.dump(y_smt, open('y_smt.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.557Z"
    }
   },
   "outputs": [],
   "source": [
    "df4['country_destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.559Z"
    }
   },
   "outputs": [],
   "source": [
    "y_over.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.561Z"
    }
   },
   "outputs": [],
   "source": [
    "X_smt = pickle.load(open('C:/Users/Henrique/repos/Airbnb/airbnb_predict_first_booking/X_smt.pkl', 'rb'))\n",
    "y_smt = pickle.load(open('C:/Users/Henrique/repos/Airbnb/airbnb_predict_first_booking/y_smt.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.564Z"
    }
   },
   "outputs": [],
   "source": [
    "#numerical data\n",
    "df43 = X_smt[ col_num ]\n",
    "\n",
    "#categorical data\n",
    "df44 = X_smt.drop(col_num, axis=1)\n",
    "df45 = pd.DataFrame(ohe.inverse_transform(df44), columns=col_cat, index=df44.index)\n",
    "\n",
    "#join numerical categorical\n",
    "df46 = pd.concat([df43, df45], axis=1)\n",
    "df46['country_destination'] = y_smt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.567Z"
    }
   },
   "outputs": [],
   "source": [
    " df51 = df46.copy() #balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.578Z"
    }
   },
   "outputs": [],
   "source": [
    " df52 = df4.copy() #unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.581Z"
    }
   },
   "outputs": [],
   "source": [
    "aux03.sum()/len(aux03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.584Z"
    }
   },
   "outputs": [],
   "source": [
    "df52.dtypes.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Hypothesis Validation - Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H01.** Em todos os destinos, os usuários levam 15 dias, em média, para fazer a primeira reserva no Airbnb, desde sua primeira ativacao.\n",
    "\n",
    "**Verdadeiro.** Em todos os destinos, os usuários até 6 dias para reservar o primeiro Airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.588Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(3, 1, 1)\n",
    "aux01 = df52[['days_from_first_active_until_booking', 'country_destination']].groupby('country_destination').median().reset_index()\n",
    "sns.barplot(x='country_destination', y='days_from_first_active_until_booking', \n",
    "             data=aux01.sort_values('days_from_first_active_until_booking'))\n",
    "\n",
    "# remove outlier\n",
    "plt.subplot(3, 1, 2)\n",
    "aux02 = df52[(df52['country_destination'] != 'NDF') & (df52['country_destination'] != 'other')]\n",
    "aux02 = aux02[['days_from_first_active_until_booking', 'country_destination']].groupby('country_destination').median().reset_index()\n",
    "sns.barplot( x='country_destination', y='days_from_first_active_until_booking', \n",
    "             data=aux02.sort_values('days_from_first_active_until_booking'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.590Z"
    }
   },
   "outputs": [],
   "source": [
    "#aux03 = df52[(df52['days_from_first_active_until_booking'] < 10) & (df52['country_destination'] == 'US')]['days_from_first_active_until_booking']\n",
    "#plt.boxplot(aux03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H02.** Em todos os destinos, os usuários levam 3 dias, em média, para fazer o cadastro no site.\n",
    "\n",
    "**Verdadeira.** Em todos os destinos, os usuários levam até 2 dias para finalizar o cadastro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.595Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "aux01 = df52[['days_from_first_active_until_account_created', 'country_destination']].groupby('country_destination').mean().reset_index()\n",
    "sns.barplot(x='country_destination', y='days_from_first_active_until_account_created', \n",
    "             data=aux01.sort_values('days_from_first_active_until_account_created'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H03.** O volume de reservas anual feitas durante o verão aumentaram 20% para destinos dentro dos USA.\n",
    "\n",
    "**False.** O Volume de reservas aumenta durante o verão entre os anos de 2010 até 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.598Z"
    }
   },
   "outputs": [],
   "source": [
    "aux01 = df52[['year_first_booking', 'month_first_booking', 'country_destination']].\\\n",
    "                groupby(['year_first_booking', 'month_first_booking', 'country_destination']). \\\n",
    "                size().reset_index().rename(columns={0:'count'})\n",
    "\n",
    "# select only summer\n",
    "aux01 = aux01[(aux01['month_first_booking'].isin([7, 8, 9])) & (aux01['country_destination'] == 'US')]\n",
    "\n",
    "aux02 = aux01[['year_first_booking', 'count']].groupby('year_first_booking').sum().reset_index()\n",
    "\n",
    "aux02['delta'] = 100*aux02['count'].pct_change().fillna(0)\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.barplot(x='year_first_booking', y='delta', data=aux02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.600Z"
    }
   },
   "outputs": [],
   "source": [
    "perc_dict = {}\n",
    "\n",
    "print(len(aux02['count']))\n",
    "\n",
    "for i in range(len(aux02['count'])):\n",
    "    if i != 4:\n",
    "        print(i)\n",
    "        y = aux02['year_first_booking'][i+1]\n",
    "        perc = ((aux02['count'][i+1]*100)/(aux02['count'][i]))-100\n",
    "        perc_dict[y] = perc\n",
    "    else:\n",
    "        exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.603Z"
    }
   },
   "outputs": [],
   "source": [
    "perc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.866Z"
    }
   },
   "outputs": [],
   "source": [
    "proof = ProfileReport(df51)\n",
    "proof.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.872Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.874Z"
    }
   },
   "outputs": [],
   "source": [
    "#dummy variable\n",
    "df5_dummy = pd.get_dummies(df5.drop(['id','country_destination'], axis=1))\n",
    "\n",
    "#join id and country destination\n",
    "df5 = pd.concat([df5[['id','country_destination']], df5_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.877Z"
    }
   },
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Feature Seleciotn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.879Z"
    }
   },
   "outputs": [],
   "source": [
    "#cols_drop = ['date_account_created', 'timestamp_first_active', 'date_first_booking', 'first_active'] # original dates\n",
    "df6 = df5.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.882Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df6.drop(['id', 'country_destination'], axis=1)\n",
    "y = df6['country_destination'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.884Z"
    }
   },
   "outputs": [],
   "source": [
    "#split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.887Z"
    }
   },
   "outputs": [],
   "source": [
    "country_destination_list = df1['country_destination'].drop_duplicates().sort_values().tolist()\n",
    "k_num = y_test.shape[0]\n",
    "country_destination_weights = df1['country_destination'].value_counts(normalize=True).sort_index().tolist()\n",
    "\n",
    "yhat_random = random.choices(population=country_destination_list, \n",
    "                             weights=country_destination_weights,\n",
    "                             k=k_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1. Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.890Z"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "acc_random = m.accuracy_score(y_test, yhat_random)\n",
    "print('Accuracy: {}'.format(acc_random))\n",
    "\n",
    "#balanced accuracy\n",
    "balanced_acc_random = m.balanced_accuracy_score(y_test, yhat_random)\n",
    "print('Balanced Accuracy: {}'.format(balanced_acc_random))\n",
    "\n",
    "#Kappa metrics\n",
    "kappa_random = m.cohen_kappa_score(y_test, yhat_random)\n",
    "print('Kappa Accuracy: {}'.format(kappa_random))\n",
    "\n",
    "#Classification report\n",
    "print( m.classification_report( y_test, yhat_random ) )\n",
    "\n",
    "#Confusion Matrix\n",
    "mt.plot_confusion_matrix( y_test, yhat_random, normalize=False, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Neural Network - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.893Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe = pp.OneHotEncoder()\n",
    "y_train_nn = ohe.fit_transform(y_train.values.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.895Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.898Z"
    }
   },
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = ml.Sequential()\n",
    "model.add(l.Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(l.Dense(12, activation='softmax'))\n",
    "\n",
    "# model compile\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(X_train, y_train_nn, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1. NN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.900Z"
    }
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "pred_nn = model.predict(X_test)\n",
    "\n",
    "#invert prediction\n",
    "yhat_nn = ohe.inverse_transform(pred_nn)\n",
    "\n",
    "#prediction prepare\n",
    "y_test_nn = y_test.to_numpy()\n",
    "yhat_nn = yhat_nn.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.903Z"
    }
   },
   "outputs": [],
   "source": [
    "#accuracy\n",
    "acc_nn = m.accuracy_score(y_test_nn, yhat_nn)\n",
    "print('Accuracy: {}'.format(acc_nn))\n",
    "\n",
    "#balanced accuracy\n",
    "balanced_acc_nn = m.balanced_accuracy_score(y_test_nn, yhat_nn)\n",
    "print('Balanced Accuracy: {}'.format(balanced_acc_nn))\n",
    "\n",
    "#Kappa metrics\n",
    "kappa_nn = m.cohen_kappa_score(y_test_nn, yhat_nn)\n",
    "print('Kappa Accuracy: {}'.format(kappa_nn))\n",
    "\n",
    "#confusion matrix\n",
    "mt.plot_confusion_matrix(y_test_nn, yhat_nn, normalize=False, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-25T22:02:10.795631Z",
     "start_time": "2021-04-25T22:02:10.777644Z"
    }
   },
   "source": [
    "### 7.2.2. NN Performance - Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.906Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate k-fold\n",
    "num_folds = 5\n",
    "kfold = ms.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=32)\n",
    "\n",
    "balanced_acc_list = []\n",
    "kappa_acc_list = []\n",
    "\n",
    "i = 1\n",
    "\n",
    "for train_ix, val_ix in kfold.split(X_train, y_train):\n",
    "    print('Fold Number: {}/{}'.format(i, num_folds))\n",
    "    \n",
    "    #get fold\n",
    "    x_train_fold = X_train.iloc[train_ix]\n",
    "    y_train_fold = y_train.iloc[train_ix]\n",
    "    \n",
    "    x_val_fold = X_train.iloc[val_ix]\n",
    "    y_val_fold = y_train.iloc[val_ix]\n",
    "    \n",
    "    #target hot-enconding\n",
    "    ohe = pp.OneHotEncoder()\n",
    "    y_train_fold_nn = ohe.fit_transform(y_train_fold.values.reshape(-1,1)).toarray()\n",
    "    \n",
    "    #model definition\n",
    "    model = ml.Sequential()\n",
    "    model.add(l.Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(l.Dense(12, activation='softmax'))\n",
    "    \n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    #training model\n",
    "    model.fit(x_train_fold, y_train_fold_nn, epochs=100, batch_size=32, verbose=0)\n",
    "    \n",
    "    #prediction\n",
    "    pred_nn = model.predict(x_val_fold)\n",
    "    yhat_nn = ohe.inverse_transform(pred_nn)\n",
    "    \n",
    "    #prepare data\n",
    "    y_test_nn = y_val_fold.to_numpy()\n",
    "    yhat_nn = yhat_nn.reshape(1, -1)[0]\n",
    "    \n",
    "    #metrics\n",
    "    ##Balanced Accuracy\n",
    "    baanced_acc_nn = m.balanced_accuracy_score(y_test_nn, yhat_nn)\n",
    "    balanced_acc_list.append(balanced_acc_nn)\n",
    "    \n",
    "    ##Kappa Metrics\n",
    "    kappa_acc_nn = m.cohen_kappa_score(y_test_nn, yhat_nn)\n",
    "    kappa_acc_list.append(kappa_acc_nn)\n",
    "    \n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.908Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(balanced_acc_list, open('balanced_acc_list.pkl','wb'))\n",
    "pickle.dump(kappa_acc_list, open('kappa_acc_list.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-05-10T01:03:31.910Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Avg Balanced Accuracy: {} +/- {}'.format(np.round(np.mean(balanced_acc_list),2),\n",
    "                                                np.round(np.std(balanced_acc_list),4)))\n",
    "print('Avg Kappa Accuracy: {} +/- {}'.format(np.round(np.mean(kappa_acc_list),2),\n",
    "                                             np.round(np.std(kappa_acc_list)),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
